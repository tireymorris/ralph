{
  "version": 4,
  "project_name": "Ralph Codebase Cleanup",
  "branch_name": "feature/clean-code-and-software-design",
  "context": "Go 1.24 project using standard testing with testify-style assertions. Project structure: main.go (entry point), internal/ packages (args, cli, config, constants, logger, prd, prompt, runner, tui, workflow), external deps include Charmbracelet Bubbletea for TUI, gofrs/flock for file locking. Testing approach: unit tests in *_test.go files, integration tests in root, use go test ./... to run all tests. Naming conventions: package names lowercase, exported functions PascalCase, private functions camelCase, constants UpperCamelCase. Code style follows Go conventions, uses structured logging with internal/logger package, error wrapping with fmt.Errorf, JSON for storage with atomic writes and file locking. Key abstractions: RunnerInterface for AI runners, Event system for UI updates, PRD struct for state management with optimistic locking versioning. Shared constants: internal/constants package contains all magic numbers with explanatory comments (EventChannelBuffer=10000, ScannerBufferSize=1MB, PipeReaderCount=2, MaxJSONRepairAttempts=2, FileLockTimeout=30s, etc.) used consistently across all packages. Input validation: Added comprehensive validation with size limits (MaxContextSize=1MB, MaxStories=1000, MaxStoryDescSize=100KB, MaxAcceptanceCriteria=50) to prevent resource exhaustion and ensure data integrity. Security: Path traversal protection in config validation to prevent malicious file access. Error context pattern: All errors now include specific operation context with file paths, model names, parameter values, and clear descriptions using consistent fmt.Errorf wrapping pattern. Logging patterns: Use RunnerInterface methods RunnerName() and CommandName() to get implementation-agnostic runner identification. Log messages should be generic (\"AI runner\", \"invoking\", \"completed\") and include runner/command as context parameters rather than hardcoding tool names. Runner log filtering: Each runner implements IsInternalLog() method to filter out implementation-specific noise. OpenCode runner filters internal service logs, Claude Code runner identifies user-facing vs internal errors, both providing cleaner output to users.",
  "stories": [
    {
      "id": "story-1",
      "title": "Add comprehensive error context",
      "description": "Enhance error handling throughout the codebase by adding proper context to all error returns. Currently many errors lack context about which operation failed, making debugging difficult. Update all fmt.Errorf calls to include relevant context like file paths, operation names, and parameter values.",
      "acceptance_criteria": ["All error returns include context about the operation", "File operations include the file path in error messages", "Network/external operations include relevant parameters", "Error contexts follow consistent format across all packages", "No generic error messages without context"],
      "test_spec": "Run `go test ./...` to ensure all existing tests pass. Add new tests to verify error messages contain expected context strings. Test error paths in config loading, file I/O, and workflow operations.",
      "priority": 1,
      "passes": true,
      "retry_count": 0
    },
    {
      "id": "story-2",
      "title": "Define and document magic numbers",
      "description": "Replace magic numbers throughout the codebase with named constants. Currently the code has hardcoded values like 10000 (event channel buffer), 1024*1024 (scanner buffer), and 2 (max JSON repair attempts) without explanation. Define these as package-level constants with explanatory comments.",
      "acceptance_criteria": ["All magic numbers replaced with named constants", "Each constant has explanatory comment documenting its purpose", "Constants are grouped logically at package level", "No numeric literals remain in code except 0, 1, -1", "Constants follow Go naming conventions (UpperCamelCase for exported)"],
      "test_spec": "Run `go test ./...` to ensure functionality unchanged. Use grep to find remaining numeric literals. Verify constants are used consistently across related files.",
      "priority": 2,
      "passes": true,
      "retry_count": 0
    },
    {
      "id": "story-3",
      "title": "Fix inconsistent logging references",
      "description": "Update logging statements that reference specific implementation details. Currently workflow.go logs 'opencode returned error' even when using Claude Code runner. Make logging generic and implementation-agnostic. Update any runner-specific references to be generic or add context about which runner is being used.",
      "acceptance_criteria": ["All logging messages are implementation-agnostic", "Runner-specific information is included via context parameters", "No hardcoded references to 'opencode' in shared code", "Logging provides clear context about operation regardless of runner", "Log messages are consistent across different code paths"],
      "test_spec": "Run tests with both OpenCode and Claude Code configurations. Verify log output contains appropriate generic messages. Check that verbose logging works correctly with both runners.",
      "priority": 3,
      "passes": true,
      "retry_count": 0
    },
    {
      "id": "story-4",
      "title": "Improve function naming and clarity",
      "description": "Rename misleading function names to better reflect their actual purpose. The runner.go has `isVerboseLine()` function that actually detects OpenCode-specific internal log patterns, not verbosity. Rename to clarify its purpose and make it configurable per runner type.",
      "acceptance_criteria": ["Functions have names that accurately describe their purpose", "No misleading names that suggest different functionality", "Runner-specific functions are properly namespaced", "Function names follow Go conventions and are self-documenting", "Public functions have clear documentation comments"],
      "test_spec": "Run `go test ./...` to ensure all tests pass. Verify that renamed functions maintain the same behavior. Check that OpenCode and Claude Code runners correctly use their respective log filtering.",
      "priority": 4,
      "passes": true,
      "retry_count": 0
    },
    {
      "id": "story-5",
      "title": "Add comprehensive input validation",
      "description": "Implement robust input validation for all external inputs including user prompts, configuration values, and PRD data fields. Currently there's limited validation on field lengths, story count limits, and potential malicious inputs. Add validation for context size limits, story field constraints, and ensure reasonable bounds to prevent resource exhaustion.",
      "acceptance_criteria": ["All user inputs validated before processing", "Context field size limited to prevent memory exhaustion", "Story count and individual field size constraints enforced", "Input validation returns clear error messages", "No unbounded resource consumption from malicious inputs", "Validation integrated into config loading and PRD operations"],
      "test_spec": "Add unit tests for validation edge cases. Test with oversized inputs, negative values, empty required fields. Verify that malicious inputs are rejected with appropriate error messages.",
      "priority": 5,
      "passes": false,
      "retry_count": 0
    },
    {
      "id": "story-6",
      "title": "Enhance test coverage and quality",
      "description": "Improve test coverage by adding comprehensive unit tests for all packages, focusing on edge cases and error paths. Current test coverage is minimal. Add tests for PRD logic edge cases (duplicate IDs, negative priorities), configuration validation, workflow error handling, and runner output parsing. Ensure tests cover both success and failure scenarios.",
      "acceptance_criteria": ["All packages have >80% test coverage", "Edge cases tested (nil inputs, empty slices, invalid values)", "Error paths tested with realistic scenarios", "Integration tests cover main workflows", "Tests are maintainable and follow Go testing conventions", "No important code paths left untested"],
      "test_spec": "Run `go test -cover ./...` to measure coverage. Use `go test -race ./...` to check for race conditions. Add benchmark tests for performance-critical paths. Ensure all tests pass with both race detection and coverage checking enabled.",
      "priority": 6,
      "passes": false,
      "retry_count": 0
    }
  ]
}